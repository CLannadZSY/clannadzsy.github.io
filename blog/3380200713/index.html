<!doctype html><html lang=en-us><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="ie=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=google-site-verification content="M1Cw9Od63LZv4K4V_iX8zomHSDnAy0-cWtfnSSas5YY"><meta name=referrer content="no-referrer-when-downgrade"><link rel=preload as=font href=https://clannad.icu/fonts/vendor/jost/jost-v4-latin-regular.woff2 type=font/woff2 crossorigin><link rel=preload as=font href=https://clannad.icu/fonts/vendor/jost/jost-v4-latin-700.woff2 type=font/woff2 crossorigin><link rel=stylesheet href=https://clannad.icu/main.f3b79dae0a6ed39bcb2df7416819da56aebaaf071bce2ff907bd8b5242dd9ca3e6e7de00aa4b736bad0ae77c8e19d71db6be4ab5e4b5d5056b02fc9ae0e0020a.css integrity="sha512-87edrgpu05vLLfdBaBnaVq66rwcbzi/5B72LUkLdnKPm594Aqktza60K53yOGdcdtr5KteS11QVrAvya4OACCg==" crossorigin=anonymous><noscript><style>img.lazyload{display:none}</style></noscript><meta name=robots content="index, follow"><meta name=googlebot content="index, follow, max-snippet:-1, max-image-preview:large, max-video-preview:-1"><meta name=bingbot content="index, follow, max-snippet:-1, max-image-preview:large, max-video-preview:-1"><title>Scrapy 永不停止的爬虫 - CL</title><meta name=description content="CLを書いて、人生を読みます。"><link rel=canonical href=https://clannad.icu/blog/3380200713/><meta name=twitter:card content="summary"><meta name=twitter:title content="Scrapy 永不停止的爬虫"><meta name=twitter:description content="在 Scrapy.Spider 中的使用
from scrapy import Request, Spider, signals from scrapy.exceptions import DontCloseSpider class TestSpider(Spider): name = 'test' start_urls = [ 'https://www.baidu.com' ] def parse(self, response, **kwargs): self.logger.info('crawled: %s', response.url) def next_request(self): req = Request( self.start_urls[0], callback=self.parse, dont_filter=True, ) self.crawler.engine.crawl(req, spider=self) def spider_idle(self): self.next_request() self.logger.info('spider idled.') raise DontCloseSpider @classmethod def from_crawler(cls, crawler, *args, **kwargs): spider = super(TestSpider, cls).from_crawler(crawler, *args, **kwargs) crawler.signals.connect(spider.spider_idle, signal=signals.spider_idle) return spider  输出日志
[scrapy.core.engine] INFO: Spider opened [scrapy."><meta name=twitter:site content="@"><meta name=twitter:creator content="@"><meta property="og:title" content="Scrapy 永不停止的爬虫"><meta property="og:description" content="在 Scrapy.Spider 中的使用
from scrapy import Request, Spider, signals from scrapy.exceptions import DontCloseSpider class TestSpider(Spider): name = 'test' start_urls = [ 'https://www.baidu.com' ] def parse(self, response, **kwargs): self.logger.info('crawled: %s', response.url) def next_request(self): req = Request( self.start_urls[0], callback=self.parse, dont_filter=True, ) self.crawler.engine.crawl(req, spider=self) def spider_idle(self): self.next_request() self.logger.info('spider idled.') raise DontCloseSpider @classmethod def from_crawler(cls, crawler, *args, **kwargs): spider = super(TestSpider, cls).from_crawler(crawler, *args, **kwargs) crawler.signals.connect(spider.spider_idle, signal=signals.spider_idle) return spider  输出日志
[scrapy.core.engine] INFO: Spider opened [scrapy."><meta property="og:type" content="article"><meta property="og:url" content="/blog/3380200713/"><meta property="article:published_time" content="2021-06-01T02:34:55+00:00"><meta property="article:modified_time" content="2021-06-01T02:34:55+00:00"><meta property="og:site_name" content="CL"><meta property="article:publisher" content="https://www.facebook.com/"><meta property="article:author" content="https://www.facebook.com/"><meta property="og:locale" content><script type=application/ld+json>{"@context":"https://schema.org","@type":"Article","mainEntityOfPage":{"@type":"WebPage","@id":"\/blog\/3380200713\/"},"headline":"Scrapy 永不停止的爬虫","image":[],"datePublished":"2021-06-01T02:34:55CET","dateModified":"2021-06-01T02:34:55CET","author":{"@type":"Organization","name":"CL"},"publisher":{"@type":"Organization","name":"CL","logo":{"@type":"ImageObject","url":"\/logo-doks.png"}},"description":""}</script><script type=application/ld+json>{"@context":"http://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Home","item":"https:\/\/clannad.icu\/"},{"@type":"ListItem","position":3,"name":"Blog","item":"https:\/\/clannad.icu\/\/blog\/"},{"@type":"ListItem","position":4,"name":"3380200713th","item":"https:\/\/clannad.icu\/\/blog\/3380200713\/"}]}</script><meta name=theme-color content="#fff"><link rel=apple-touch-icon sizes=180x180 href=https://clannad.icu/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=https://clannad.icu/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=https://clannad.icu/favicon-16x16.png><link rel=manifest href=https://clannad.icu/site.webmanifest></head><body class="blog single"><div class="header-bar fixed-top"></div><header class="navbar fixed-top navbar-expand-md navbar-light"><div class=container><input class="menu-btn order-0" type=checkbox id=menu-btn>
<label class="menu-icon d-md-none" for=menu-btn><span class=navicon></span></label><a class="navbar-brand order-1 order-md-0 me-auto" href=https://clannad.icu/>CL</a>
<button id=mode class="btn btn-link order-2 order-md-4" type=button aria-label="Toggle mode">
<span class=toggle-dark><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-moon"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg></span><span class=toggle-light><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-sun"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></span></button><ul class="navbar-nav social-nav order-3 order-md-5"><li class=nav-item><a class=nav-link href=https://github.com/CLannadZSY><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-github"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37.0 00-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44.0 0020 4.77 5.07 5.07.0 0019.91 1S18.73.65 16 2.48a13.38 13.38.0 00-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07.0 005 4.77 5.44 5.44.0 003.5 8.55c0 5.42 3.3 6.61 6.44 7A3.37 3.37.0 009 18.13V22"/></svg><span class="ms-2 visually-hidden">GitHub</span></a></li></ul><div class="collapse navbar-collapse order-4 order-md-1"><ul class="navbar-nav main-nav me-auto order-5 order-md-2"><li class="nav-item active"><a class=nav-link href=https://clannad.icu/blog/>Blog</a></li></ul><div class="break order-6 d-md-none"></div><form class="navbar-form flex-grow-1 order-7 order-md-3"><input id=userinput class="form-control is-search" type=search placeholder="Search docs..." aria-label="Search docs..." autocomplete=off><div id=suggestions class="shadow bg-white rounded"></div></form></div></div></header><div class="wrap container" role=document><div class=content><div class="row justify-content-center"><div class="col-md-12 col-lg-10 col-xl-8"><article><div class=blog-header><h1>Scrapy 永不停止的爬虫</h1><p><small>Posted June 1, 2021 by
<a class="stretched-link position-relative" href=https://clannad.icu/contributors/clannadzsy/>clannadzsy</a>
&nbsp;&dash;&nbsp;
<strong>2&nbsp;min read</strong></small><p></div><p class=lead></p><p>在 <code>Scrapy.Spider</code> 中的使用</p><pre><code class=language-python>from scrapy import Request, Spider, signals
from scrapy.exceptions import DontCloseSpider


class TestSpider(Spider):
    name = 'test'

    start_urls = [
        'https://www.baidu.com'
    ]

    def parse(self, response, **kwargs):
        self.logger.info('crawled: %s', response.url)

    def next_request(self):
        req = Request(
            self.start_urls[0],
            callback=self.parse,
            dont_filter=True,
        )
        self.crawler.engine.crawl(req, spider=self)

    def spider_idle(self):
        self.next_request()
        self.logger.info('spider idled.')
        raise DontCloseSpider

    @classmethod
    def from_crawler(cls, crawler, *args, **kwargs):
        spider = super(TestSpider, cls).from_crawler(crawler, *args, **kwargs)
        crawler.signals.connect(spider.spider_idle, signal=signals.spider_idle)
        return spider

</code></pre><p>输出日志</p><pre><code class=language-bash>
[scrapy.core.engine] INFO: Spider opened
[scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
[scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://www.baidu.com&gt; (referer: None)
[test] INFO: crawled: https://www.baidu.com
[test] INFO: spider idled.
[scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://www.baidu.com&gt; (referer: None)
[test] INFO: crawled: https://www.baidu.com
[test] INFO: spider idled.
[scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://www.baidu.com&gt; (referer: None)
[test] INFO: crawled: https://www.baidu.com
[test] INFO: spider idled.
[scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://www.baidu.com&gt; (referer: None)
[test] INFO: crawled: https://www.baidu.com
[test] INFO: spider idled.
</code></pre><p>在 <code>RedisSpider</code> 中使用</p><pre><code class=language-python>import time
import scrapy
from amz_spider.db_conf import REDIS_URL
from scrapy_redis.spiders import RedisSpider

from scrapy.exceptions import DontCloseSpider, CloseSpider


class TestSpider(RedisSpider):
    name = 'test'

    redis_key = f'{name}:start_urls'

    start_urls = [
        'https://www.baidu.com'
    ]

    custom_settings = {

        'SCHEDULER': 'scrapy_redis.scheduler.Scheduler',
        'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter',
        'SCHEDULER_PERSIST': False,
        # redis 连接
        'REDIS_URL': REDIS_URL
    }

    wait_count = 0

    def parse(self, response, **kwargs):
        self.logger.info('crawled: %s', response.url)

    def make_requests_from_url(self, d):
        return scrapy.Request(self.start_urls[0], callback=self.parse)

    def spider_idle(self):
        if self.server.exists(self.redis_key):
            # 重置次数
            self.wait_count = 0
            self.schedule_next_requests()
            raise DontCloseSpider
        else:
            # 队列为空, 等待一小时, 每分钟检测一次, 是否有新的任务添加, 如果没有才退出
            if self.wait_count &lt; 60:
                time.sleep(60)
                self.wait_count += 1
                raise DontCloseSpider
            raise CloseSpider

</code></pre></article></div></div><script src=https://utteranc.es/client.js repo=CLannadZSY/clannadzsy.github.io issue-term=title theme=github-light crossorigin=anonymous async></script></div></div><footer class="footer text-muted"><div class=container><div class=row><div class="col-lg-8 order-last order-lg-first"><ul class=list-inline><li class=list-inline-item>Copyright © 2020-present <a href=https://github.com/CLannadZSY/>clannadzsy</a></li></ul></div><div class="col-lg-8 order-first order-lg-last text-lg-end"><ul class=list-inline></ul></div></div></div></footer><script src=https://clannad.icu/js/highlight.min.2c793eb7599ae4975966407f455873eca25c0dd1146f2ba6a8ca933c3ee5a244f8e3a48c5b73694a76709db65ff3e7eedf2a55fc3b0c03510b2eca2b8635c8da.js integrity="sha512-LHk+t1ma5JdZZkB/RVhz7KJcDdEUbyumqMqTPD7lokT446SMW3NpSnZwnbZf8+fu3ypV/DsMA1ELLsorhjXI2g==" crossorigin=anonymous defer></script><script src=https://clannad.icu/main.min.7ab523108435955765bcb88a0ee704f412ba01646b5478e84f3b9feb24f0ce750a14c3f7bd9a62408fe21e41996d361a9eb29f77e85dfe77b7e17f7623bd3a97.js integrity="sha512-erUjEIQ1lVdlvLiKDucE9BK6AWRrVHjoTzuf6yTwznUKFMP3vZpiQI/iHkGZbTYanrKfd+hd/ne34X92I706lw==" crossorigin=anonymous defer></script><script src=https://clannad.icu/index.min.2ab4b3ba0de0d49f020a532eda219cbbae89f190caed914c8e9e8d0b0022a730fed8c6d6fbb9ad71f5a0ffab295a9fa0dd4410e342625571c9a7be78084cc899.js integrity="sha512-KrSzug3g1J8CClMu2iGcu66J8ZDK7ZFMjp6NCwAipzD+2MbW+7mtcfWg/6spWp+g3UQQ40JiVXHJp754CEzImQ==" crossorigin=anonymous defer></script></body></html>